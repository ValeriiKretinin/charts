apiVersion: v1
kind: Secret
metadata:
  name: {{ include "airflow.fullname" . }}-config-envs
  labels:
    app: {{ include "airflow.labels.app" . }}
    chart: {{ include "airflow.labels.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
## we must use `data` rather than `stringData` (see: https://github.com/helm/helm/issues/10010)
data:
  ## ================
  ## Linux Configs
  ## ================
  TZ: {{ "Etc/UTC" | b64enc | quote }}

  ## ================
  ## Database Configs
  ## ================
  ## database host/port
  {{- if include "airflow.pgbouncer.should_use" . }}
  DATABASE_HOST: {{ printf "%s-pgbouncer.%s.svc.%s" (include "airflow.fullname" .) (.Release.Namespace) (.Values.airflow.clusterDomain) | b64enc | quote }}
  DATABASE_PORT: {{ "6432" | b64enc | quote }}
  {{- else if .Values.postgres.enabled }}
  {{- $pgSvc := ( .Values.postgres.serviceName | default (include "airflow.postgres.fullname" .) ) -}}
  DATABASE_HOST: {{ printf "%s.%s.svc.%s" $pgSvc (.Release.Namespace) (.Values.airflow.clusterDomain) | b64enc | quote }}
  DATABASE_PORT: {{ "5432" | b64enc | quote }}
  {{- else }}
  DATABASE_HOST: {{ .Values.externalDatabase.host | toString | b64enc | quote }}
  DATABASE_PORT: {{ .Values.externalDatabase.port | toString | b64enc | quote }}
  {{- end }}

  ## database configs
  {{- if .Values.postgres.enabled }}
  DATABASE_DB: {{ include "airflow.postgres.envValue" (list . "POSTGRES_DB") | toString | b64enc | quote }}
  ## for embedded Postgres, export DATABASE_USER here so pods pick it via envFrom
  DATABASE_USER: {{ include "airflow.postgres.envValue" (list . "POSTGRES_USER") | toString | b64enc | quote }}
  {{- if not .Values.postgres.existingSecret }}
  ## for embedded Postgres without separate Secret, export DATABASE_PASSWORD here too
  DATABASE_PASSWORD: {{ include "airflow.postgres.envValue" (list . "POSTGRES_PASSWORD") | toString | b64enc | quote }}
  {{- end }}
  {{- else }}
  DATABASE_DB: {{ .Values.externalDatabase.database | toString | b64enc | quote }}
  DATABASE_PROPERTIES: {{ .Values.externalDatabase.properties | toString | b64enc | quote }}
  {{- end }}

  {{- /* in other cases, these variables are set in the "airflow.env" template */ -}}
  {{- if not .Values.postgres.enabled }}
  {{- if or (not .Values.externalDatabase.userSecret ) (not .Values.externalDatabase.passwordSecret) }}

  ## database credentials (from plain-text helm values)
  {{- if not .Values.externalDatabase.userSecret }}
  DATABASE_USER: {{ .Values.externalDatabase.user | toString | b64enc | quote }}
  {{- end }}
  {{- if not .Values.externalDatabase.passwordSecret }}
  DATABASE_PASSWORD: {{ .Values.externalDatabase.password | toString | b64enc | quote }}
  {{- end }}
  {{- end }}
  {{- end }}

  ## bash command which echos the URL encoded value of $DATABASE_USER
  DATABASE_USER_CMD: {{ `echo "${DATABASE_USER}" | python3 -c "import urllib.parse; encoded_user = urllib.parse.quote(input()); print(encoded_user)"` | b64enc | quote }}

  ## bash command which echos the URL encoded value of $DATABASE_PASSWORD
  DATABASE_PASSWORD_CMD: {{ `echo "${DATABASE_PASSWORD}" | python3 -c "import urllib.parse; encoded_pass = urllib.parse.quote(input()); print(encoded_pass)"` | b64enc | quote }}

  ## bash command which echos the DB connection string in SQLAlchemy format
  {{- if .Values.postgres.enabled }}
  DATABASE_SQLALCHEMY_CMD: {{ `echo -n "postgresql+psycopg2://$(eval $DATABASE_USER_CMD):$(eval $DATABASE_PASSWORD_CMD)@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_DB}"` | b64enc | quote }}
  {{- else if eq "postgres" .Values.externalDatabase.type }}
  DATABASE_SQLALCHEMY_CMD: {{ `echo -n "postgresql+psycopg2://$(eval $DATABASE_USER_CMD):$(eval $DATABASE_PASSWORD_CMD)@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_DB}${DATABASE_PROPERTIES}"` | b64enc | quote }}
  {{- else if eq "mysql" .Values.externalDatabase.type }}
  DATABASE_SQLALCHEMY_CMD: {{ `echo -n "mysql+mysqldb://$(eval $DATABASE_USER_CMD):$(eval $DATABASE_PASSWORD_CMD)@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_DB}${DATABASE_PROPERTIES}"` | b64enc | quote }}
  {{- end }}

  ## bash command which echos the DB connection string in Celery result_backend format
  {{- if .Values.postgres.enabled }}
  DATABASE_CELERY_CMD: {{ `echo -n "db+postgresql://$(eval $DATABASE_USER_CMD):$(eval $DATABASE_PASSWORD_CMD)@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_DB}"` | b64enc | quote }}
  {{- else if eq "postgres" .Values.externalDatabase.type }}
  DATABASE_CELERY_CMD: {{ `echo -n "db+postgresql://$(eval $DATABASE_USER_CMD):$(eval $DATABASE_PASSWORD_CMD)@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_DB}${DATABASE_PROPERTIES}"` | b64enc | quote }}
  {{- else if eq "mysql" .Values.externalDatabase.type }}
  DATABASE_CELERY_CMD: {{ `echo -n "db+mysql://$(eval $DATABASE_USER_CMD):$(eval $DATABASE_PASSWORD_CMD)@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_DB}${DATABASE_PROPERTIES}"` | b64enc | quote }}
  {{- end }}

  {{- if include "airflow.pgbouncer.should_use" . }}
  ## bash command which echos the DB connection string in `psql` cli format
  ## NOTE: uses `127.0.0.1` as the host because this is only used in the pgbouncer liveness probe
  ##       and minikube does not allow pods to access their own `cluster.local` service so would otherwise fail
  DATABASE_PSQL_CMD: {{ `echo -n "postgresql://$(eval $DATABASE_USER_CMD):$(eval $DATABASE_PASSWORD_CMD)@127.0.0.1:${DATABASE_PORT}/${DATABASE_DB}${DATABASE_PROPERTIES}"` | b64enc | quote }}
  {{- end }}

  ## ================
  ## Redis Configs
  ## ================
  ## Always compute Redis connection pieces when Redis is used (embedded or external).
  {{ if .Values.redis.enabled }}
  {{- $redisBase := include "airflow.redis.fullname" . -}}
  {{- $redisSvc := ( .Values.redis.serviceName | default (printf "%s%s" $redisBase (.Values.redis.serviceNameSuffix | default "")) ) -}}
  REDIS_HOST: {{ printf "%s.%s.svc.%s" $redisSvc (.Release.Namespace) (.Values.airflow.clusterDomain) | b64enc | quote }}
  REDIS_PORT: {{ "6379" | b64enc | quote }}
  REDIS_DBNUM: {{ "1" | b64enc | quote }}
  {{- if not .Values.redis.existingSecret }}
  ## embedded redis password (empty value allowed)
  REDIS_PASSWORD: {{ .Values.redis.password | toString | b64enc | quote }}
  {{- end }}
  {{ else }}
  REDIS_HOST: {{ .Values.externalRedis.host | toString | b64enc | quote }}
  REDIS_PORT: {{ .Values.externalRedis.port | toString | b64enc | quote }}
  REDIS_DBNUM: {{ .Values.externalRedis.databaseNumber | toString | b64enc | quote }}
  REDIS_PROPERTIES: {{ .Values.externalRedis.properties | toString | b64enc | quote }}
  {{- if not .Values.externalRedis.passwordSecret }}
  ## credentials (from plain-text helm values)
  REDIS_PASSWORD: {{ .Values.externalRedis.password | toString | b64enc | quote }}
  {{- end }}
  {{ end }}

  ## bash command which echos the URL encoded value of $REDIS_PASSWORD
  ## NOTE: if $REDIS_PASSWORD is non-empty, prints `:${REDIS_PASSWORD}@`, else ``
  REDIS_PASSWORD_CMD: {{ `echo "${REDIS_PASSWORD}" | python3 -c "import sys, urllib.parse; data=sys.stdin.read().strip(); encoded=urllib.parse.quote(data); print(f\":{encoded}@\") if len(encoded) > 0 else print(\"\")"` | b64enc | quote }}

  ## bash command which echos the Redis connection string
  REDIS_CONNECTION_CMD: {{ `echo -n "redis://$(eval $REDIS_PASSWORD_CMD)${REDIS_HOST}:${REDIS_PORT}/${REDIS_DBNUM}${REDIS_PROPERTIES}"` | b64enc | quote }}

  ## ================
  ## Airflow Configs (General)
  ## ================
  AIRFLOW__CORE__DAGS_FOLDER: {{ include "airflow.dags.path" . | b64enc | quote }}
  ## Let Airflow use default hostname resolution (like Bitnami does)
  ## Each pod will use its own HOSTNAME environment variable from Kubernetes
  {{- $executors := join "," .Values.airflow.executors }}
  AIRFLOW__CORE__EXECUTOR: {{ $executors | toString | b64enc | quote }}
  {{- if .Values.airflow.fernetKey }}
  AIRFLOW__CORE__FERNET_KEY: {{ .Values.airflow.fernetKey | toString | b64enc | quote }}
  {{- end }}
  {{- /* Ensure a stable API secret key across all components (needed for JWT verification by SDK) */ -}}
  {{- /* Check if user defined AIRFLOW__API__SECRET_KEY in extraEnv - if so, skip our defaults */ -}}
  {{- $userDefinedApiSecret := false }}
  {{- if .Values.airflow.extraEnv }}
  {{- range .Values.airflow.extraEnv }}
    {{- if eq .name "AIRFLOW__API__SECRET_KEY" }}
      {{- $userDefinedApiSecret = true }}
    {{- end }}
  {{- end }}
  {{- end }}
  {{- /* Only set default if user hasn't provided their own via config or extraEnv */ -}}
  {{- if and (not (hasKey .Values.airflow.config "AIRFLOW__API__SECRET_KEY")) (not $userDefinedApiSecret) }}
  {{- if .Values.airflow.apiSecretKey }}
  AIRFLOW__API__SECRET_KEY: {{ .Values.airflow.apiSecretKey | toString | b64enc | quote }}
  {{- else }}
  {{- $existingCfg := (lookup "v1" "Secret" .Release.Namespace (printf "%s-config-envs" (include "airflow.fullname" .))) }}
  {{- if and $existingCfg (hasKey $existingCfg.data "AIRFLOW__API__SECRET_KEY") }}
  AIRFLOW__API__SECRET_KEY: {{ index $existingCfg.data "AIRFLOW__API__SECRET_KEY" | quote }}
  {{- else }}
  AIRFLOW__API__SECRET_KEY: {{ randAlphaNum 50 | b64enc | quote }}
  {{- end }}
  {{- end }}
  {{- end }}

  {{- /* JWT Secret for Airflow 3 API authentication (like Bitnami does) */ -}}
  {{- if and (not (hasKey .Values.airflow.config "AIRFLOW__API_AUTH__JWT_SECRET")) (not $userDefinedApiSecret) }}
  {{- if .Values.airflow.apiSecretKey }}
  AIRFLOW__API_AUTH__JWT_SECRET: {{ .Values.airflow.apiSecretKey | toString | b64enc | quote }}
  {{- else }}
  {{- $existingCfg := (lookup "v1" "Secret" .Release.Namespace (printf "%s-config-envs" (include "airflow.fullname" .))) }}
  {{- if and $existingCfg (hasKey $existingCfg.data "AIRFLOW__API_AUTH__JWT_SECRET") }}
  AIRFLOW__API_AUTH__JWT_SECRET: {{ index $existingCfg.data "AIRFLOW__API_AUTH__JWT_SECRET" | quote }}
  {{- else }}
  AIRFLOW__API_AUTH__JWT_SECRET: {{ randAlphaNum 50 | b64enc | quote }}
  {{- end }}
  {{- end }}
  {{- end }}
  AIRFLOW__API__HOST: {{ "0.0.0.0" | b64enc | quote }}
  AIRFLOW__API__PORT: {{ "8080" | b64enc | quote }}
  AIRFLOW__CELERY__FLOWER_PORT: {{ "5555" | b64enc | quote }}
  ## Default API auth backends include JWT so SDK tokens work out of the box
  {{- $api_backends := (default "" .Values.airflow.config.AIRFLOW__API__AUTH_BACKENDS) -}}
  AIRFLOW__API__AUTH_BACKENDS: {{ (default "airflow.providers.fab.auth_manager.api.auth.backend.jwt,airflow.providers.fab.auth_manager.api.auth.backend.session,airflow.providers.fab.auth_manager.api.auth.backend.basic_auth" $api_backends) | b64enc | quote }}
  {{- if not .Values.airflow.config.AIRFLOW__CORE__AUTH_MANAGER }}
  ## Default to FAB auth manager (Bitnami-like UX); SimpleAuthManager is not recommended for prod
  AIRFLOW__CORE__AUTH_MANAGER: {{ "airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager" | b64enc | quote }}
  {{- end }}

  ## Ensure FAB permissions are updated on startup (avoids None perms on fresh installs)
  {{- if not .Values.airflow.config.AIRFLOW__WEBSERVER__UPDATE_FAB_PERMS }}
  AIRFLOW__WEBSERVER__UPDATE_FAB_PERMS: {{ "True" | b64enc | quote }}
  {{- end }}

  {{- if and (.Values.dags.gitSync.enabled) (not .Values.airflow.config.AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL) }}
  ## refresh the dags folder at the same frequency as git-sync
  AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: {{ .Values.dags.gitSync.syncWait | toString | b64enc | quote }}
  {{- end }}

  {{- if .Values.airflow.config.AIRFLOW__API__WORKERS }}
  AIRFLOW__API__WORKERS: {{ .Values.airflow.config.AIRFLOW__API__WORKERS | toString | b64enc | quote }}
  {{- end }}
  {{- if .Values.airflow.config.AIRFLOW__API__WORKER_TIMEOUT }}
  AIRFLOW__API__WORKER_TIMEOUT: {{ .Values.airflow.config.AIRFLOW__API__WORKER_TIMEOUT | toString | b64enc | quote }}
  {{- end }}
  {{- if and (.Values.airflow.config.AIRFLOW__API__SSL_CERT) (.Values.airflow.config.AIRFLOW__API__SSL_KEY) }}
  AIRFLOW__API__SSL_CERT: {{ .Values.airflow.config.AIRFLOW__API__SSL_CERT | toString | b64enc | quote }}
  AIRFLOW__API__SSL_KEY: {{ .Values.airflow.config.AIRFLOW__API__SSL_KEY | toString | b64enc | quote }}
  {{- end }}

  ## ================
  ## Airflow Configs (Database)
  ## ================
  AIRFLOW__CORE__SQL_ALCHEMY_CONN_CMD: {{ `bash -c 'eval "$DATABASE_SQLALCHEMY_CMD"'` | b64enc | quote }}
  ## `core.sql_alchemy_conn` moved to `database.sql_alchemy_conn` in airflow 2.3.0
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN_CMD: {{ `bash -c 'eval "$DATABASE_SQLALCHEMY_CMD"'` | b64enc | quote }}

  ## ================
  ## Airflow Configs (Triggerer)
  ## ================
  {{- if include "airflow.triggerer.should_use" . }}
  {{- if not .Values.airflow.config.AIRFLOW__TRIGGERER__DEFAULT_CAPACITY }}
  AIRFLOW__TRIGGERER__DEFAULT_CAPACITY: {{ .Values.triggerer.capacity | toString | b64enc | quote }}
  {{- end }}
  {{- end }}

  ## ================
  ## Airflow Configs (Logging)
  ## ================
  {{- if .Values.airflow.legacyCommands }}
  AIRFLOW__CORE__BASE_LOG_FOLDER: {{ .Values.logs.path | toString | b64enc | quote }}
  AIRFLOW__CORE__DAG_PROCESSOR_MANAGER_LOG_LOCATION: {{ printf "%s/dag_processor_manager/dag_processor_manager.log" .Values.logs.path | b64enc | quote }}
  {{- else }}
  AIRFLOW__LOGGING__BASE_LOG_FOLDER: {{ .Values.logs.path | toString | b64enc | quote }}
  {{- if include "airflow.dag_processor.should_use" . }}
  ## Airflow 3: use DAG_PROCESSOR_LOG_LOCATION
  AIRFLOW__LOGGING__DAG_PROCESSOR_LOG_LOCATION: {{ printf "%s/dag_processor/dag_processor.log" .Values.logs.path | b64enc | quote }}
  {{- else }}
  ## Airflow 2: keep manager log location for backward-compat
  AIRFLOW__LOGGING__DAG_PROCESSOR_MANAGER_LOG_LOCATION: {{ printf "%s/dag_processor_manager/dag_processor_manager.log" .Values.logs.path | b64enc | quote }}
  {{- end }}
  {{- end }}
  AIRFLOW__SCHEDULER__CHILD_PROCESS_LOG_DIRECTORY: {{ printf "%s/scheduler" .Values.logs.path | b64enc | quote }}


  ## ================
  ## Airflow Configs (Celery)
  ## ================
  {{- if or (include "airflow.executor.celery_like" .) .Values.workers.enabled }}
  AIRFLOW__LOGGING__WORKER_LOG_SERVER_PORT: {{ "8793" | b64enc | quote }}
  # `logging.worker_log_server_port` replaced `celery.worker_log_server_port` in airflow 2.2.0
  AIRFLOW__CELERY__WORKER_LOG_SERVER_PORT: {{ "8793" | b64enc | quote }}
  AIRFLOW__CELERY__BROKER_URL_CMD: {{ `bash -c 'eval "$REDIS_CONNECTION_CMD"'` | b64enc | quote }}
  AIRFLOW__CELERY__RESULT_BACKEND_CMD: {{ `bash -c 'eval "$DATABASE_CELERY_CMD"'` | b64enc | quote }}
  {{- end }}

  ## ================
  ## Airflow Configs (Kubernetes)
  ## ================
  ## Always provide namespace and cluster info for stable hostnames in logs URLs
  {{- if not (or .Values.airflow.config.AIRFLOW__KUBERNETES__NAMESPACE .Values.airflow.config.AIRFLOW__KUBERNETES_EXECUTOR__NAMESPACE) }}
  AIRFLOW__KUBERNETES__NAMESPACE: {{ .Release.Namespace | toString | b64enc | quote }}
  AIRFLOW__KUBERNETES_EXECUTOR__NAMESPACE: {{ .Release.Namespace | toString | b64enc | quote }}
  {{- end }}
  AIRFLOW__LOCAL__WORKER_SERVICE: {{ printf "%s-worker" (include "airflow.fullname" .) | b64enc | quote }}
  AIRFLOW__CLUSTER_DOMAIN: {{ .Values.airflow.clusterDomain | toString | b64enc | quote }}
  {{- if include "airflow.executor.kubernetes_like" . }}
  {{- if not (or .Values.airflow.config.AIRFLOW__KUBERNETES__WORKER_CONTAINER_REPOSITORY .Values.airflow.config.AIRFLOW__KUBERNETES_EXECUTOR__WORKER_CONTAINER_REPOSITORY) }}
  AIRFLOW__KUBERNETES__WORKER_CONTAINER_REPOSITORY: {{ .Values.airflow.image.repository | toString | b64enc | quote }}
  AIRFLOW__KUBERNETES_EXECUTOR__WORKER_CONTAINER_REPOSITORY: {{ .Values.airflow.image.repository | toString | b64enc | quote }}
  {{- end }}
  {{- if not (or .Values.airflow.config.AIRFLOW__KUBERNETES__WORKER_CONTAINER_TAG .Values.airflow.config.AIRFLOW__KUBERNETES_EXECUTOR__WORKER_CONTAINER_TAG) }}
  AIRFLOW__KUBERNETES__WORKER_CONTAINER_TAG: {{ .Values.airflow.image.tag | toString | b64enc | quote }}
  AIRFLOW__KUBERNETES_EXECUTOR__WORKER_CONTAINER_TAG: {{ .Values.airflow.image.tag | toString | b64enc | quote }}
  {{- end }}
  {{- if not (or .Values.airflow.config.AIRFLOW__KUBERNETES__POD_TEMPLATE_FILE .Values.airflow.config.AIRFLOW__KUBERNETES_EXECUTOR__POD_TEMPLATE_FILE) }}
  AIRFLOW__KUBERNETES__POD_TEMPLATE_FILE: {{ "/opt/airflow/pod_templates/pod_template.yaml" | b64enc | quote }}
  AIRFLOW__KUBERNETES_EXECUTOR__POD_TEMPLATE_FILE: {{ "/opt/airflow/pod_templates/pod_template.yaml" | b64enc | quote }}
  {{- end }}

  {{- if .Values.airflow.legacyCommands }}
  {{- if not .Values.airflow.config.AIRFLOW__KUBERNETES__ENV_FROM_CONFIGMAP_REF }}
  AIRFLOW__KUBERNETES__ENV_FROM_SECRET_REF: {{ printf "%s-config" (include "airflow.fullname" .) | b64enc | quote }}
  {{- end }}
  {{- if (not .Values.airflow.config.AIRFLOW__KUBERNETES__WORKER_SERVICE_ACCOUNT_NAME) }}
  AIRFLOW__KUBERNETES__WORKER_SERVICE_ACCOUNT_NAME: {{ include "airflow.serviceAccountName" . | b64enc | quote }}
  {{- end }}
  {{- end }}
  {{- end }}

  ## ================
  ## User Configs
  ## ================
  {{- range $k, $v := .Values.airflow.config }}
  {{ $k | quote }}: {{ $v | toString | b64enc | quote }}
  {{- end }}
